---
layout: post
toc: true
title: "智能随想-关于AGI的一些浅显观点和假设"
categories: 人工智能
tags: [AGI, 知识体系, 逻辑自洽, 编码]
author:

- David

---

从3年前开始，笔者对于人工智能模型的长期发展前景，保持前所未有的乐观，甚至认为AGI可能就在未来的十几年就能产生或者出现，3年过去了，从去年开始出现的大规模
模型的功能，似乎也进一步加强了我的这种认识，但随着深入理解现在的模型CLIP，DIFFUSION，BERT，GPT等，笔者觉得这个认识可能需要退一步，必须保持足够清醒。

首先第一点，我们对于知识的认识，好像还是从模型的设计环节跳开了，或者说不被重视，将模型"溶解"
更多的数据，挖掘隐层语义向量的特定关系，作为了当前模型研究的主要方向。例如，文本转图片，
图片转文本，文本转文本等，对这些多模态或者内容转换的任务设计问题解决范式的时候，都还停留在10年前的表示学习的认知上进行，认为一段128维或者更高维度的语义向量，可
以表达整个任务所需要的全部信息，笔者认为这目前看起来是无可厚非的，虽然目前的模型已经十分的复杂，全过程都是"编码-解码"
的逻辑架构，可是易见的是这种架构做到的编解码的自回归任务，解决的问题都还是表象的。

笔者觉得Hinton在17年capsuleNet的工作，就是在强调解构知识。虽然end2end的训练模型方式，对数据进行了重新编码再目前的学习任务中效果是最好的，但同时也是
黑盒式的，是封闭式的，然而我们对于知识的学习，这是在一个逻辑自洽的知识体系中开放式进行的。 熟悉的人可能了解，目前我们模型的构建方式是单次大模型结合巨量
数据的训练模式。由于数据的体量巨大，间接导致无法进行进一步人为有效的筛选，所以是全量数据一起进行训练的，模型可以学习到信息统一式
编码的方式，例如文字之间的词和字的位置、概率关系，图像中像素块的位置，概率关系等。这一预训练模式被认为为模型前置构建了一套可以输出跟人进行信息交流的基础模
型。进一步为了使模型更加符合于某一特定状态和领域的输出，我们再通过设计下游模型，结合少量的有监督数据对模型进行微调，改变预训练模型本身内在的编码方式，使其输出满足
预期。但这样的过程，并不符合我们对于学习的理解，最直接的表现就是这样的学习，构建的知识表达体系是封闭式的，一旦没有校验的标签，模型就完全丧失了判断能力，若需要获得全量的
标签学习，这是不可能。例如：当前非常火爆的生成模型，可以想象，在模型生成内容的过程中，高维度混杂语义编码，实现对于自然语言中各种不同文字token间关联的信息进行概率评估，从而反馈出在输入
一段序列后，如何一步一步输出接下来关联的文字，只是模型无法获得概念性的理解或者抽象。这点最直接的表现就是他对于概念性的描述，只存在于训练语料中是否包含了
对应的文字关系数据，并不会从自洽的逻辑概念知识中，通过不断反溃-推断这样的机制，来完善这样的概念。再比如：ChatGPT这样的生成模型，可以通过思维链的启
发式prompt的方式来训练模型去解决简单的逻辑任务，但从笔者的多次反复的评估中，即便是在优化prompt的方式中，依旧需要通过输入较为逻辑封闭的prompt来获得
模型输出正确的结果，并且在明显给出错误的prompt的前提下，模型会顺着错误逻辑的方向进行回答，而主动放弃了原本自己已经回答正确的结果。从这些角度上来讲，
缺乏自洽逻辑说明当前模型还只是一个encoder-decoder的工具，当然，这样的工具具有强大的地方，要溶解如此巨量的数据，依然是一件非常不容易的事情。

![image](https://thumbnail1.baidupcs.com/thumbnail/d9fc8b45bp5e6fa888719b9abef06f0e?fid=1260329066-250528-562401397999033&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-sTYLI5zFtN2izaNbncdwTZOzBZE%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)
![image](https://thumbnail1.baidupcs.com/thumbnail/32883677cib9b3b50d1fee8a7beea2ff?fid=1260329066-250528-113707552978799&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-woA9pmIRlm2CUdhbX1DgiHZV9Xw%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)


![image](https://thumbnail1.baidupcs.com/thumbnail/26fd7c18co50dca820233229752265bf?fid=1260329066-250528-719205138507748&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-KuHA4Ro0Cev4dB5tIRxtpunAunc%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)
![image](https://thumbnail1.baidupcs.com/thumbnail/9dfe8c94bk0966405324a0c2cae457f0?fid=1260329066-250528-172645395739936&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-Sjtp9Cq7oRmj%2bcBOzd7AfuhFF1k%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)
![image](https://thumbnail1.baidupcs.com/thumbnail/a2f1b74den380539c1ae5d6891868bb5?fid=1260329066-250528-909036784578147&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-ETMzbzRPxpVgAePKEObTiTqrTc8%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)
![image](https://thumbnail1.baidupcs.com/thumbnail/ac2337998g0d5268cf40aed8f0a9d32f?fid=1260329066-250528-562512996728830&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-9QEOL%2fJ7z0N7WIF9LevQDq9D8%2bs%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)
![image](https://thumbnail1.baidupcs.com/thumbnail/bdafc4de6h44829968199ee98392aca6?fid=1260329066-250528-1004078494894561&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-t%2b832LeNGoLGJgKB%2b3Uh3KCUf4M%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)
![image](https://thumbnail1.baidupcs.com/thumbnail/68e89c556u8a32bab79d970846100ff5?fid=1260329066-250528-53939997881937&rt=pr&sign=FDTAER-DCb740ccc5511e5e8fedcff06b081203-BC8Gb8Ruy2bbFySgsOYT4LMLDP0%3d&expires=8h&chkbd=0&chkv=0&dp-logid=9123696939382996897&dp-callid=0&time=1676422800&size=c1280_u720&quality=90&vuk=1260329066&ft=image&autopolicy=1)

<sub>_上图所示是笔者对chatgpt提出的2个关于逻辑方面的问题。可以看出来chatgpt是在尝试做分析，这样的分析是可以通过思维链（CoT）的prompt语料进行对应
的训练学习，但模型依然是缺少对于自己分析结果的判断能力。_</sub>

具备逻辑自洽的推理能力是对于开放式知识进行抽象的第一步，即便是设计可以进行自洽逻辑推理的学习策略，我们原始对于构造出来一套知晓万事的人工智能模
型的预想也可能是破灭的，因为训练的数据本身可能存在这多种结果导向完全矛盾的自洽逻辑，这是
笔者觉得进一步提升AGI模型面临的第一个不太能被逾越的壁垒。如果我们的考虑是构建一个足够强大的模型，让它可以解释或者学习所有事情，那么这样的模型可能
并不能实现，这对于一个个体的人脑来说就是一件非常困难的事情。两种相悖的概念并存于认知、知识里边，必定会造成支撑其概念的底层逻辑的改变，这种改变对于知识编
码的方式来说，可能是非常巨大的，甚至导致输出是不确定的。但是如果我们需要对模型进行进一步的微调，让其形成独立的一套逻辑自洽的知识、概念体系，那么首先我们
如何来对海量的信息数据进行筛选，其次，我们如何通过有限的训练数据，让其具备足够的代表性，可以明确哪些是"正确的"逻辑，哪些是"
错误的"逻辑，再次，目前的神经网络模型，当前的神经网络模型的隐层语义向量依旧是非语义信息，还不太具备可以对抽象的概念进行严格的逻辑推理的能力。
笔者理解这依然是需要基本的知识体系的，且学习过程是循序渐进的，例如：我们只有学习了什么是集合、函数，
才能理解什么是导数，什么是积分和微分，这样的过程如果是反过来的，那么我们可能很难进行学习，所以我们现在累积的人造数据，是否真实，
是否能够作为模型的学习原料，可能需要更深度和全面地审视。

另外一个笔者认为不太能逾越的壁垒，是一旦模型遇到新抽象化概念的时候，我们如何帮助模型对新的虚假概念进行甄别，这可能是一个更加复杂的命题。在新的知识和概念的发现
的过程中，人不仅可以通过基础知识体系，来对新概念和知识进行逻辑自洽的学习，更加重要的是，可以主动结合真实的实践活动对目标知识进行检验，从而获得
真实的反馈，虽然目前的强化学习已经在人型机器人的活动、自动驾驶等多种场景下，实现了部分有条件的与环境接触反馈的学习，但是对于复杂概念性的验证实践，在笔
者认为目前看起来，这样的事情显得十分科幻。从这个角度出发，对于考虑通过AGI来实现某些科学方向的短期爆炸性突破的预期，自然也是显得想的简单了，或者这样的
思考，需要特定的科学方向具备一定的可靠研究范式，例如蛋白质的空间结构预测等。

笔者认为对于AGI来说，虽然目前看起来，从知识以及自洽的逻辑学习来说，可能是存在较强的认知限制，但是退一步来说，即便无法构建出知晓且符合全部甚至部分人理解
认知的超级智能大脑，但是似乎这并不影响现在的模型实现进行简单的文字理解和输出，如果希望期待它能够解决更加复杂的问题，我们可能还是需要构建有限知识边界的
人工智能模型。
